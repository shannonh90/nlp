{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shannon Hamilton, ANLP 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: K-Means vs LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports + reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# below code adapted from Brandon Rose's blog post on clustering: \n",
    "# http://brandonrose.org/clustering\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code to break up my txt file of pubmed articles into a single list\n",
    "# each article saved as an item in the list\n",
    "# sourced here, http://stackoverflow.com/questions/22364468/how-to-split-txt-file-to-multiple-file-base-on-content\n",
    "\n",
    "import re\n",
    "\n",
    "def open_chunk(readfunc, delimiter, chunksize=1024):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/17508761/190597\n",
    "    readfunc(chunksize) should return a string.\n",
    "    \"\"\"\n",
    "    remainder = ''\n",
    "    for chunk in iter(lambda: readfunc(chunksize), ''):\n",
    "        pieces = re.split(delimiter, remainder + chunk)\n",
    "        for piece in pieces[:-1]:\n",
    "            yield piece\n",
    "        remainder = pieces[-1]\n",
    "    if remainder:\n",
    "        yield remainder\n",
    "\n",
    "with open('pubmed_depression.txt', 'r') as infile:\n",
    "    pubmed_list = []\n",
    "    chunks = open_chunk(infile.read, delimiter=r'(PMID.*)')\n",
    "    for i, (chunk, delim) in enumerate(zip(*[chunks]*2)):\n",
    "        chunk = chunk+delim\n",
    "        chunk = chunk.strip()\n",
    "        if chunk:\n",
    "            pubmed_list.append(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming, Lemmatizing and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in pubmed_list:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 80582 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.14 s, sys: 44.8 ms, total: 4.19 s\n",
      "Wall time: 4.21 s\n",
      "(250, 308)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, max_features=200000,\n",
    "                                 min_df=0.1, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(pubmed_list) #fit the vectorizer to text\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K-Means, I changed num_clusters to 3, 5, 10, 20 and found 10 to provide the best results. Honestly, the clusters are still a bit muddled (my corpous is a set of 250 pubmed articles, all on mental health). It was interesting to see studies clustered that are US (#8, 9) based versus Canada-based (#6, 7), or themes of studies (ie: suicide/9, anxiety/4, bipolar/3, women/1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 283 ms, sys: 3.33 ms, total: 286 ms\n",
      "Wall time: 289 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: b'study', b'intervention', b'trials', b'effect', b'therapy', b'outcomes', b'treatments', b'systematic', b'participants', b'psychological',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1 words: b'health', b'mental', b'women', b'mental', b'study', b'department', b'public', b'public', b'prevalent', b\"'s\",\n",
      "\n",
      "\n",
      "\n",
      "Cluster 2 words: b'effect', b'therapy', b'electronic', b'electronic', b'addressing', b'conditions', b'ltd.', b'study', b'disorder', b'ltd.',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 3 words: b'disorder', b'response', b'institute', b'usa', b'behavioral', b'research', b'department', b'brain', b'psychiatry', b'process',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 4 words: b'anxiety', b'depression', b'symptoms', b'department', b'study', b'united', b'associated', b'prevalent', b'health', b'patients',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 5 words: b'patients', b'disease', b'center', b'carefully', b'factors', b'medical', b'medical', b'medicinal', b'risk', b'risk',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 6 words: b'drug', b'disease', b'disorder', b'treatments', b'clinical', b'symptoms', b'therapy', b'canada', b'use', b\"'s\",\n",
      "\n",
      "\n",
      "\n",
      "Cluster 7 words: b'pain', b'canada', b'chronic', b'factors', b'patients', b'centre', b'study', b'risk', b'psychological', b'medicinal',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 8 words: b'usa', b'department', b'medicinal', b'psychiatry', b'patients', b'department', b'treatments', b'school', b'behavioral', b'medical',\n",
      "\n",
      "\n",
      "\n",
      "Cluster 9 words: b'suicide', b'behavioral', b'risk', b'psychiatry', b'clinical', b'department', b'department', b'research', b'effect', b'usa',\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "#     print(\"Cluster %d titles:\" % i, end='')\n",
    "#     for title in frame.ix[i]['title'].values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I appreciated being able to compare results from LDA to K-Means. LDA clusters were also a bit muddled, but again, I think clinical trial themes seem to bubble up pretty well: diabetes/2, maternal + women/3, chronic pain/4, sleep-related/6, suicide/7, anxiety/8. I chose to oput 10 clusters so that I could compare results more easily with K-Means. Exciting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def strip_proppers(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word.islower()]\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/gensim-0.13.3-py3.5-macosx-10.6-x86_64.egg/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 9.04 ms, total: 1.96 s\n",
      "Wall time: 1.98 s\n",
      "CPU times: user 1.76 s, sys: 13.2 ms, total: 1.77 s\n",
      "Wall time: 1.79 s\n",
      "CPU times: user 148 ms, sys: 843 Âµs, total: 149 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "\n",
    "# with open('pubmed_depression_bodytext.txt', 'r') as handle:\n",
    "#     raw = handle.read().replace('\\n', ' ')\n",
    "\n",
    "#remove proper names\n",
    "%time preprocess = [strip_proppers(doc) for doc in pubmed_list]\n",
    "\n",
    "#tokenize\n",
    "%time tokenized_text = [tokenize_and_stem(text) for text in preprocess]\n",
    "\n",
    "#remove stop words\n",
    "%time texts = [[word for word in text if word not in stopwords] for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a Gensim dictionary from the texts\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "#remove extremes (similar to the min/max df step used when creating the tf-idf matrix)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "\n",
    "#convert the dictionary to a bag of words corpus for reference\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 2.53 s, total: 3min 37s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=10, id2word=dictionary, update_every=5, chunksize=10000, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"studi\" + 0.015*\"intervent\" + 0.015*\"review\" + 0.012*\"includ\" + 0.011*\"health\" + 0.010*\"provid\" + 0.009*\"use\" + 0.009*\"effect\" + 0.008*\"popul\" + 0.008*\"address\"'),\n",
       " (1,\n",
       "  '0.008*\"massag\" + 0.007*\"function\" + 0.006*\"mental\" + 0.006*\"health\" + 0.006*\"evid\" + 0.006*\"risk\" + 0.005*\"stress\" + 0.005*\"opioid\" + 0.005*\"process\" + 0.005*\"diet\"'),\n",
       " (2,\n",
       "  '0.013*\"disord\" + 0.013*\"treatment\" + 0.011*\"patient\" + 0.011*\"diseas\" + 0.010*\"studi\" + 0.008*\"review\" + 0.008*\"includ\" + 0.008*\"diabet\" + 0.007*\"process\" + 0.007*\"clinic\"'),\n",
       " (3,\n",
       "  '0.010*\"studi\" + 0.009*\"stroke\" + 0.008*\"matern\" + 0.008*\"develop\" + 0.007*\"disord\" + 0.007*\"mechan\" + 0.007*\"women\" + 0.006*\"function\" + 0.005*\"dure\" + 0.005*\"process\"'),\n",
       " (4,\n",
       "  '0.026*\"pain\" + 0.020*\"chronic\" + 0.015*\"de\" + 0.011*\"dystonia\" + 0.010*\"du\" + 0.009*\"antibodi\" + 0.008*\"intervent\" + 0.008*\"patient\" + 0.008*\"factor\" + 0.008*\"prevent\"'),\n",
       " (5,\n",
       "  '0.024*\"studi\" + 0.019*\"effect\" + 0.018*\"intervent\" + 0.016*\"trial\" + 0.012*\"therapi\" + 0.011*\"includ\" + 0.011*\"evid\" + 0.010*\"treatment\" + 0.010*\"particip\" + 0.010*\"use\"'),\n",
       " (6,\n",
       "  '0.014*\"work\" + 0.013*\"health\" + 0.011*\"shift\" + 0.010*\"effect\" + 0.010*\"insomnia\" + 0.010*\"worker\" + 0.009*\"ketamin\" + 0.008*\"mental\" + 0.008*\"recommend\" + 0.007*\"problem\"'),\n",
       " (7,\n",
       "  '0.027*\"studi\" + 0.015*\"patient\" + 0.013*\"review\" + 0.010*\"use\" + 0.010*\"suicid\" + 0.009*\"systemat\" + 0.008*\"search\" + 0.008*\"symptom\" + 0.008*\"effect\" + 0.008*\"includ\"'),\n",
       " (8,\n",
       "  '0.014*\"studi\" + 0.013*\"review\" + 0.012*\"anxieti\" + 0.012*\"disord\" + 0.011*\"symptom\" + 0.011*\"effect\" + 0.009*\"includ\" + 0.009*\"treatment\" + 0.009*\"intervent\" + 0.007*\"address\"'),\n",
       " (9,\n",
       "  '0.013*\"mental\" + 0.010*\"health\" + 0.009*\"risk\" + 0.009*\"review\" + 0.008*\"studi\" + 0.008*\"disord\" + 0.008*\"increas\" + 0.007*\"popul\" + 0.007*\"higher\" + 0.007*\"among\"')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2: Word2Vec vs WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For nouns, I believe Word2Vec provides nouns more inline with the context of my corpus. For adjectives, I believe Word2Vec also is better than WordNet. There appears to be more word options and again, are more in line with the context of my corpus. For verbs, I think that WordNet did better than Word2Vec. There appears to be more verb options available, and Word2Vec appears to just put forth other forms of the same verb (ie: cures > cures, curing, cured).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.data import find\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('studies', 0.7211395502090454),\n",
       " ('Study', 0.6836080551147461),\n",
       " ('survey', 0.6731963753700256),\n",
       " ('researchers', 0.6250616312026978),\n",
       " ('research', 0.6238202452659607)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['study'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intervene', 0.5795313119888306),\n",
       " ('intervening', 0.5319258570671082),\n",
       " ('intervened', 0.4465080797672272),\n",
       " ('assistance', 0.42715123295783997),\n",
       " ('mobilization', 0.3966519832611084)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['intervention'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reviewed', 0.6630408763885498),\n",
       " ('reviewing', 0.6609559059143066),\n",
       " ('reviews', 0.6379557251930237),\n",
       " ('evaluation', 0.6035541296005249),\n",
       " ('assessment', 0.5333109498023987)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['review'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patients', 0.7280630469322205),\n",
       " ('physicians', 0.6102133393287659),\n",
       " ('physician', 0.6056575775146484),\n",
       " ('clinical', 0.550094485282898),\n",
       " ('surgical', 0.5453905463218689)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['patient'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suicides', 0.6633865833282471),\n",
       " ('homicide', 0.513701856136322),\n",
       " ('murder', 0.49831241369247437),\n",
       " ('death', 0.47814804315567017),\n",
       " ('murders', 0.4759059548377991)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['suicide'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('survey.n.01'), Synset('study.n.02'), Synset('report.n.01')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('study', wn.NOUN)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('intervention.n.01'),\n",
       " Synset('intervention.n.02'),\n",
       " Synset('interposition.n.02')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('intervention', wn.NOUN)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('reappraisal.n.01'), Synset('review.n.02'), Synset('follow-up.n.03')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('review', wn.NOUN)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('patient.n.01'), Synset('affected_role.n.01')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('patient', wn.NOUN)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('suicide.n.01'), Synset('suicide.n.02')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('suicide', wn.NOUN)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('systematically', 0.5535138845443726),\n",
       " ('methodical', 0.5095993876457214),\n",
       " ('deliberate', 0.5030157566070557),\n",
       " ('thorough', 0.4970399737358093),\n",
       " ('systematized', 0.4735804498195648)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['systematic'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mental', 0.6324292421340942),\n",
       " ('psychologically', 0.6209654211997986),\n",
       " ('emotional', 0.5921927690505981),\n",
       " ('physiological', 0.5291099548339844),\n",
       " ('physical', 0.5243164300918579)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['psychological'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doctors', 0.6195696592330933),\n",
       " ('physician', 0.5994016528129578),\n",
       " ('Medical', 0.5921540856361389),\n",
       " ('physicians', 0.5749360918998718),\n",
       " ('dental', 0.5676089525222778)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['medical'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eager', 0.722114622592926),\n",
       " ('fearful', 0.643116295337677),\n",
       " ('nervous', 0.6418448686599731),\n",
       " ('worried', 0.6220002174377441),\n",
       " ('impatient', 0.6138770580291748)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['anxious'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Effective', 0.6084572076797485),\n",
       " ('efficient', 0.5855873823165894),\n",
       " ('ineffective', 0.5252822637557983),\n",
       " ('efficacious', 0.505646824836731),\n",
       " ('economical', 0.4952201247215271)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['effective'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('systematic.a.01'), Synset('taxonomic.a.01')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('systematic', wn.ADJ)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('psychological.s.01'), Synset('psychological.a.02')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('psychological', wn.ADJ)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('medical.a.01'), Synset('medical.a.02'), Synset('aesculapian.a.01')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('medical', wn.ADJ)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('anxious.s.01'), Synset('anxious.s.02')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('anxious', wn.ADJ)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('effective.a.01'), Synset('effective.s.02'), Synset('effective.s.03')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('effective', wn.ADJ)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('treating', 0.7725892663002014),\n",
       " ('treats', 0.687384843826294),\n",
       " ('treated', 0.673922598361969),\n",
       " ('Treat', 0.6268018484115601),\n",
       " ('treatment', 0.511717677116394)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['treat'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intervened', 0.6794320940971375),\n",
       " ('intervention', 0.5795313715934753),\n",
       " ('intervening', 0.5529994368553162),\n",
       " ('meddle', 0.5135860443115234),\n",
       " ('respond', 0.48485830426216125)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['intervene'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('studies', 0.7211395502090454),\n",
       " ('Study', 0.6836080551147461),\n",
       " ('survey', 0.6731963753700256),\n",
       " ('researchers', 0.6250616312026978),\n",
       " ('research', 0.6238202452659607)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['study'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reviewed', 0.6630408763885498),\n",
       " ('reviewing', 0.6609559059143066),\n",
       " ('reviews', 0.6379557251930237),\n",
       " ('evaluation', 0.6035541296005249),\n",
       " ('assessment', 0.5333109498023987)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['review'], topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cures', 0.7962284088134766),\n",
       " ('curing', 0.6621212959289551),\n",
       " ('cured', 0.6239017844200134),\n",
       " ('remedy', 0.5670593976974487),\n",
       " ('antidote', 0.5099565982818604)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['cure'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('treat.v.01'), Synset('process.v.01'), Synset('treat.v.03')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('treat', wn.VERB)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('intervene.v.01'), Synset('intervene.v.02'), Synset('intervene.v.03')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('intervene', wn.VERB)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('analyze.v.01'), Synset('study.v.02'), Synset('study.v.03')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('study', wn.VERB)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('review.v.01'), Synset('review.v.02'), Synset('review.v.03')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('review', wn.VERB)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bring_around.v.02'), Synset('cure.v.02'), Synset('cure.v.03')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cure', wn.VERB)[0:3]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
